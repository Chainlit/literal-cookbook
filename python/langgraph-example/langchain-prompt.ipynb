{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.schema.runnable.config import RunnableConfig\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "import os\n",
    "from literalai import LiteralClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "print(os.getenv(\"LITERAL_API_KEY\"))\n",
    "print(os.getenv(\"TAVILY_API_KEY\"))\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "literalai_client = LiteralClient()\n",
    "literalai_cb = literalai_client.langchain_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Option 1: Load the weather assistant prompt JSON ----\n",
    "with open('weather-assistant-prompt.json', 'r') as file:\n",
    "    weather_assistant_prompt = json.load(file)\n",
    "\n",
    "prompt = literalai_client.api.get_or_create_prompt(\n",
    "    name=weather_assistant_prompt[\"name\"], \n",
    "    template_messages=weather_assistant_prompt[\"template_messages\"],\n",
    "    tools=weather_assistant_prompt[\"tools\"],\n",
    "    settings=weather_assistant_prompt[\"settings\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Option 2: Load the weather assistant prompt from LiteralAI ----\n",
    "# prompt = literalai_client.api.get_prompt(name=\"weather-assistant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"createdAt\": \"2024-10-01T14:06:14.323Z\",\n",
      "    \"id\": \"0bf0ef39-81bc-412f-9039-b8987ac9ba91\",\n",
      "    \"name\": \"weather-assistant\",\n",
      "    \"provider\": \"\",\n",
      "    \"settings\": {\n",
      "        \"model\": \"gpt-4o-mini\",\n",
      "        \"temperature\": 0.5\n",
      "    },\n",
      "    \"templateMessages\": [\n",
      "        {\n",
      "            \"content\": \"You are a weather assistant.\",\n",
      "            \"role\": \"system\",\n",
      "            \"uuid\": \"e2bfc8ef-eb36-4555-b788-4f90b6d14803\"\n",
      "        }\n",
      "    ],\n",
      "    \"tools\": [\n",
      "        {\n",
      "            \"function\": {\n",
      "                \"description\": \"Get the current weather\",\n",
      "                \"name\": \"get_current_weather\",\n",
      "                \"parameters\": {\n",
      "                    \"properties\": {\n",
      "                        \"format\": {\n",
      "                            \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
      "                            \"enum\": [\n",
      "                                \"celsius\",\n",
      "                                \"fahrenheit\"\n",
      "                            ],\n",
      "                            \"type\": \"string\"\n",
      "                        },\n",
      "                        \"location\": {\n",
      "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
      "                            \"type\": \"string\"\n",
      "                        }\n",
      "                    },\n",
      "                    \"required\": [\n",
      "                        \"location\",\n",
      "                        \"format\"\n",
      "                    ],\n",
      "                    \"type\": \"object\"\n",
      "                }\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "        }\n",
      "    ],\n",
      "    \"type\": \"CHAT\",\n",
      "    \"updatedAt\": \"\",\n",
      "    \"url\": \"\",\n",
      "    \"variables\": [],\n",
      "    \"variablesDefaultValues\": null,\n",
      "    \"version\": 0,\n",
      "    \"versionDesc\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messages input to the LLM\n",
    "langchain_prompt = prompt.to_langchain_chat_prompt_template()\n",
    "messages = langchain_prompt.format_messages()+ [HumanMessage(content=\"what is the weather in london?\")]\n",
    "\n",
    "# Configure the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=prompt.settings[\"model\"], \n",
    "    temperature=prompt.settings[\"temperature\"]\n",
    "    )\n",
    "\n",
    "# Bind the tools to the LLM\n",
    "llm_with_tools =  llm.bind_tools(prompt.tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_V1Nu6B0BBr9E44qvDVXq5CfF', 'function': {'arguments': '{\"format\":\"celsius\",\"location\":\"London\"}', 'name': 'get_current_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 94, 'total_tokens': 114, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-61ecddf7-c69d-49bf-b7c7-2458821b89ab-0', tool_calls=[{'name': 'get_current_weather', 'args': {'format': 'celsius', 'location': 'London'}, 'id': 'call_V1Nu6B0BBr9E44qvDVXq5CfF', 'type': 'tool_call'}], usage_metadata={'input_tokens': 94, 'output_tokens': 20, 'total_tokens': 114})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run the LLM with the callback\n",
    "llm_with_tools.invoke(\n",
    "    messages, \n",
    "    config=RunnableConfig(callbacks=[literalai_cb])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
